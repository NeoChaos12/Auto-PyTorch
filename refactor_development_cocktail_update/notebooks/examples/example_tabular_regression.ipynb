{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tabular Regression\n\nThe following example shows how to fit a sample classification model\nwith AutoPyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport tempfile as tmp\nimport typing\nimport warnings\n\nfrom sklearn.datasets import make_regression\n\nfrom autoPyTorch.data.tabular_feature_validator import TabularFeatureValidator\n\nos.environ['JOBLIB_TEMP_FOLDER'] = tmp.gettempdir()\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['OPENBLAS_NUM_THREADS'] = '1'\nos.environ['MKL_NUM_THREADS'] = '1'\n\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom sklearn import model_selection, preprocessing\n\nfrom autoPyTorch.api.tabular_regression import TabularRegressionTask\nfrom autoPyTorch.datasets.tabular_dataset import TabularDataset\nfrom autoPyTorch.utils.hyperparameter_search_space_update import HyperparameterSearchSpaceUpdates\n\n\ndef get_search_space_updates():\n    \"\"\"\n    Search space updates to the task can be added using HyperparameterSearchSpaceUpdates\n    Returns:\n        HyperparameterSearchSpaceUpdates\n    \"\"\"\n    updates = HyperparameterSearchSpaceUpdates()\n    updates.append(node_name=\"data_loader\",\n                   hyperparameter=\"batch_size\",\n                   value_range=[16, 512],\n                   default_value=32)\n    updates.append(node_name=\"lr_scheduler\",\n                   hyperparameter=\"CosineAnnealingLR:T_max\",\n                   value_range=[50, 60],\n                   default_value=55)\n    updates.append(node_name='network_backbone',\n                   hyperparameter='ResNetBackbone:dropout',\n                   value_range=[0, 0.5],\n                   default_value=0.2)\n    return updates\n\n\nif __name__ == '__main__':\n    ############################################################################\n    # Data Loading\n    # ============\n\n    # Get the training data for tabular regression\n    # X, y = datasets.fetch_openml(name=\"cholesterol\", return_X_y=True)\n\n    # Use dummy data for now since there are problems with categorical columns\n    X, y = make_regression(\n        n_samples=5000,\n        n_features=4,\n        n_informative=3,\n        n_targets=1,\n        shuffle=True,\n        random_state=0\n    )\n\n    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n        X,\n        y,\n        random_state=1,\n    )\n\n    # Scale the regression targets to have zero mean and unit variance.\n    # This is important for Neural Networks since predicting large target values would require very large weights.\n    # One can later rescale the network predictions like this: y_pred = y_pred_scaled * y_train_std + y_train_mean\n    y_train_mean = y_train.mean()\n    y_train_std = y_train.std()\n\n    y_train_scaled = (y_train - y_train_mean) / y_train_std\n    y_test_scaled = (y_test - y_train_mean) / y_train_std\n\n    ############################################################################\n    # Build and fit a regressor\n    # ==========================\n    api = TabularRegressionTask(\n        delete_tmp_folder_after_terminate=False,\n        search_space_updates=get_search_space_updates()\n    )\n    api.search(\n        X_train=X_train,\n        y_train=y_train_scaled,\n        X_test=X_test.copy(),\n        y_test=y_test_scaled.copy(),\n        optimize_metric='r2',\n        total_walltime_limit=500,\n        func_eval_time_limit=50,\n        traditional_per_total_budget=0\n    )\n\n    ############################################################################\n    # Print the final ensemble performance\n    # ====================================\n    print(api.run_history, api.trajectory)\n    y_pred_scaled = api.predict(X_test)\n\n    # Rescale the Neural Network predictions into the original target range\n    y_pred = y_pred_scaled * y_train_std + y_train_mean\n    score = api.score(y_pred, y_test)\n\n    print(score)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}